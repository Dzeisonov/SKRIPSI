{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tgOOKWK59dL"
      },
      "source": [
        "# Data Loading (MobileNetV3 Large)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_giFkyx46LUC",
        "outputId": "d83e7b75-8278-4fe6-e71e-69ab40a247eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Random seed set to 42 and parallelism disabled for reproducibility.\n",
            "Nama kelas: ['A 801 T', 'BL', 'BM', 'CLS 02', 'JF 03 TA', 'JF 08 ST', 'K 406 CTG', 'K 407 MH', 'K 409 GWC', 'V 688 CA', 'V 697 GKU', 'V TUL', 'Y 316 FA', 'Y 321 C', 'Y 327 GKU']\n",
            "Jumlah kelas: 15\n",
            "Loading images from: /content/drive/MyDrive/Dataset_Skripsi_Augmented_200_Kran_15/train\n",
            "Loading images from: /content/drive/MyDrive/Dataset_Skripsi_Augmented_200_Kran_15/val\n",
            "Loading images from: /content/drive/MyDrive/Dataset_Skripsi_Augmented_200_Kran_15/test\n",
            "\n",
            "Total gambar train: 3000\n",
            "Total gambar validation: 301\n",
            "Total gambar test: 320\n",
            "\n",
            "PROSES 1 SELESAI: Data MobileNetV3 siap dari direktori yang sudah di-augmentasi.\n",
            "\n",
            "Verifikasi Distribusi Data:\n",
            "Distribusi jumlah data per kelas di setiap split:\n",
            "        Kelas  Jumlah Train  Jumlah Validasi  Jumlah Test  Total per Kelas\n",
            "0     A 801 T           200               16           17              233\n",
            "1          BL           200               15           17              232\n",
            "2          BM           200               16           18              234\n",
            "3      CLS 02           200               15           16              231\n",
            "4    JF 03 TA           200               16           17              233\n",
            "5    JF 08 ST           200               25           27              252\n",
            "6   K 406 CTG           200               21           22              243\n",
            "7    K 407 MH           200               30           31              261\n",
            "8   K 409 GWC           200               16           17              233\n",
            "9    V 688 CA           200               34           35              269\n",
            "10  V 697 GKU           200               21           22              243\n",
            "11      V TUL           200               25           27              252\n",
            "12   Y 316 FA           200               18           19              237\n",
            "13    Y 321 C           200               15           16              231\n",
            "14  Y 327 GKU           200               18           19              237\n",
            "15      TOTAL          3000              301          320             3621\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# PROSES 1: PERSIAPAN DATA (KHUSUS UNTUK MOBILENETV3)\n",
        "# ==============================================================================\n",
        "\n",
        "# Langkah 1.1: Install Library\n",
        "!pip install -q albumentations\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "from collections import Counter\n",
        "import albumentations as A\n",
        "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
        "import random\n",
        "\n",
        "# Langkah 1.2: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Langkah 1.3: Definisi Path dan Parameter\n",
        "DATASET_DIR = '/content/drive/MyDrive/Dataset_Skripsi_Augmented_200_Kran_15'\n",
        "# DATASET_DIR = '/content/drive/MyDrive/Dataset_Skripsi_Augmented_200_Kran_15_6_transformasi'\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "SEED_VALUE = 42\n",
        "def set_seed(seed=42):\n",
        "  \"\"\"\n",
        "  Mengatur seed dan menonaktifkan parallelism untuk hasil yang fully deterministic.\n",
        "  \"\"\"\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  tf.random.set_seed(seed)\n",
        "\n",
        "  # Menjalankan operasi TF pada satu thread untuk menghilangkan randomness dari parallelism\n",
        "  tf.config.threading.set_inter_op_parallelism_threads(1)\n",
        "  tf.config.threading.set_intra_op_parallelism_threads(1)\n",
        "\n",
        "  print(f\"Random seed set to {seed} and parallelism disabled for reproducibility.\")\n",
        "\n",
        "set_seed(SEED_VALUE)\n",
        "\n",
        "# Langkah 1.4: Ambil Nama Kelas dari Struktur Direktori Train\n",
        "train_base_dir = os.path.join(DATASET_DIR, 'train')\n",
        "class_dirs = sorted([d for d in os.listdir(train_base_dir) if os.path.isdir(os.path.join(train_base_dir, d))])\n",
        "class_map = {name: i for i, name in enumerate(class_dirs)}\n",
        "\n",
        "class_names = class_dirs\n",
        "print(f\"Nama kelas: {class_names}\")\n",
        "NUM_CLASSES = len(class_names)\n",
        "print(f\"Jumlah kelas: {NUM_CLASSES}\")\n",
        "\n",
        "# Global lists untuk verifikasi distribusi data\n",
        "train_labels, val_labels, test_labels = [], [], []\n",
        "\n",
        "# Langkah 1.5: Transformasi Gambar\n",
        "basic_transform = A.Compose([\n",
        "    A.Resize(height=IMAGE_SIZE[0], width=IMAGE_SIZE[1])\n",
        "])\n",
        "\n",
        "# Langkah 1.6: Custom Data Generator\n",
        "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, directory, class_map, batch_size, transform, num_classes, shuffle=True, store_global_labels=None):\n",
        "        self.directory = directory\n",
        "        self.class_map = class_map\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transform\n",
        "        self.num_classes = num_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self._load_image_paths()\n",
        "        self.on_epoch_end()\n",
        "\n",
        "        if store_global_labels is not None:\n",
        "            store_global_labels.extend(self.labels)\n",
        "\n",
        "    def _load_image_paths(self):\n",
        "        \"\"\"Memuat path gambar dari direktori yang diberikan.\"\"\"\n",
        "        print(f\"Loading images from: {self.directory}\")\n",
        "        for class_name in sorted(self.class_map.keys()):\n",
        "            class_path = os.path.join(self.directory, class_name)\n",
        "            if os.path.isdir(class_path):\n",
        "                class_idx = self.class_map[class_name]\n",
        "                for fname in sorted(os.listdir(class_path)):\n",
        "                    if fname.lower().endswith('.jpg'):\n",
        "                        fpath = os.path.join(class_path, fname)\n",
        "                        self.image_paths.append(fpath)\n",
        "                        self.labels.append(class_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Menghitung jumlah batch per epoch.\"\"\"\n",
        "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Menghasilkan satu batch data.\"\"\"\n",
        "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch_paths = [self.image_paths[i] for i in indexes]\n",
        "        batch_labels = [self.labels[i] for i in indexes]\n",
        "        batch_images = []\n",
        "\n",
        "        for path in batch_paths:\n",
        "            img = Image.open(path).convert('RGB')\n",
        "            img_cv = np.array(img)\n",
        "            transformed = self.transform(image=img_cv) # Resize gambar\n",
        "            batch_images.append(transformed['image'])\n",
        "\n",
        "        # Preprocessing khusus MobileNetV3 Large\n",
        "        batch_images = preprocess_input(np.array(batch_images, dtype=np.float32))\n",
        "        batch_labels = tf.keras.utils.to_categorical(batch_labels, num_classes=self.num_classes)\n",
        "        return batch_images, batch_labels\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Mengacak indeks di akhir setiap epoch.\"\"\"\n",
        "        self.indexes = np.arange(len(self.image_paths))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "# Langkah 1.7: Inisialisasi Generator\n",
        "train_generator = CustomDataGenerator(\n",
        "    directory=os.path.join(DATASET_DIR, 'train'),\n",
        "    class_map=class_map,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=basic_transform,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    shuffle=True,\n",
        "    store_global_labels=train_labels\n",
        ")\n",
        "\n",
        "val_generator = CustomDataGenerator(\n",
        "    directory=os.path.join(DATASET_DIR, 'val'),\n",
        "    class_map=class_map,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=basic_transform,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    shuffle=False,\n",
        "    store_global_labels=val_labels\n",
        ")\n",
        "\n",
        "test_generator = CustomDataGenerator(\n",
        "    directory=os.path.join(DATASET_DIR, 'test'),\n",
        "    class_map=class_map,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=basic_transform,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    shuffle=False,\n",
        "    store_global_labels=test_labels\n",
        ")\n",
        "\n",
        "print(f\"\\nTotal gambar train: {len(train_generator.image_paths)}\")\n",
        "print(f\"Total gambar validation: {len(val_generator.image_paths)}\")\n",
        "print(f\"Total gambar test: {len(test_generator.image_paths)}\")\n",
        "\n",
        "print(\"\\nPROSES 1 SELESAI: Data MobileNetV3 siap dari direktori yang sudah di-augmentasi.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# Verifikasi Distribusi Data di Setiap Split\n",
        "# ==============================================================================\n",
        "print(\"\\nVerifikasi Distribusi Data:\")\n",
        "\n",
        "# Menghitung jumlah kemunculan setiap label di setiap set\n",
        "train_counts = Counter(train_labels)\n",
        "val_counts = Counter(val_labels)\n",
        "test_counts = Counter(test_labels)\n",
        "\n",
        "# Membuat tabel untuk visualisasi yang mudah dibaca\n",
        "distribusi_data = {\n",
        "    \"Kelas\": class_names,\n",
        "    \"Jumlah Train\": [train_counts.get(i, 0) for i in range(len(class_names))],\n",
        "    \"Jumlah Validasi\": [val_counts.get(i, 0) for i in range(len(class_names))],\n",
        "    \"Jumlah Test\": [test_counts.get(i, 0) for i in range(len(class_names))],\n",
        "}\n",
        "df_distribusi = pd.DataFrame(distribusi_data)\n",
        "df_distribusi[\"Total per Kelas\"] = df_distribusi[\"Jumlah Train\"] + df_distribusi[\"Jumlah Validasi\"] + df_distribusi[\"Jumlah Test\"]\n",
        "\n",
        "# Menambahkan baris total di bagian bawah\n",
        "total_row = {\n",
        "    \"Kelas\": \"TOTAL\",\n",
        "    \"Jumlah Train\": sum(df_distribusi[\"Jumlah Train\"]),\n",
        "    \"Jumlah Validasi\": sum(df_distribusi[\"Jumlah Validasi\"]),\n",
        "    \"Jumlah Test\": sum(df_distribusi[\"Jumlah Test\"]),\n",
        "    \"Total per Kelas\": sum(df_distribusi[\"Total per Kelas\"])\n",
        "}\n",
        "df_distribusi = pd.concat([df_distribusi, pd.DataFrame([total_row])], ignore_index=True)\n",
        "\n",
        "print(\"Distribusi jumlah data per kelas di setiap split:\")\n",
        "print(df_distribusi.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvu6XXLqTZUD"
      },
      "source": [
        "# MobileNetV3 Large Tanpa Decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZagcDQFceuGS",
        "outputId": "15b6c8e5-6108-420f-88db-99b6354ac6f2"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# PROSES 2 & 3: PEMBANGUNAN, PELATIHAN, EVALUASI, DAN PENYIMPANAN MODEL\n",
        "# ==============================================================================\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
        "from tensorflow.keras.applications import MobileNetV3Large\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Daftar nilai dropout yang akan diuji\n",
        "dropout_values = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "\n",
        "# Direktori utama untuk menyimpan hasil\n",
        "base_output_dir = '/content/drive/MyDrive/hasil_eksperimen_dropout_mobilenetv3_large'\n",
        "os.makedirs(base_output_dir, exist_ok=True)\n",
        "\n",
        "for dropout_rate in dropout_values:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"MEMULAI EKSPERIMEN DENGAN DROPOUT = {dropout_rate} (MobileNetV3-Large)\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    output_dir = os.path.join(base_output_dir, f'dropout_{dropout_rate}')\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    base_model = MobileNetV3Large(input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3), include_top=False, weights='imagenet')\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(dropout_rate, seed=SEED_VALUE)(x)\n",
        "    outputs = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "    model_mobilenet_final = Model(inputs=inputs, outputs=outputs)\n",
        "    model_mobilenet_final.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    print(\"Arsitektur Model:\")\n",
        "    model_mobilenet_final.summary()\n",
        "\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    print(f\"\\nMemulai pelatihan model dengan dropout = {dropout_rate}...\")\n",
        "    history = model_mobilenet_final.fit(train_generator, epochs=50, validation_data=val_generator, callbacks=[early_stopping], verbose=1)\n",
        "    print(f\"\\nPelatihan model dengan dropout = {dropout_rate} telah selesai.\")\n",
        "\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    plt.subplot(1, 2, 1); plt.plot(history.history['accuracy'], label='Akurasi Pelatihan'); plt.plot(history.history['val_accuracy'], label='Akurasi Validasi'); plt.title(f'Grafik Akurasi (Dropout = {dropout_rate})'); plt.xlabel('Epoch'); plt.ylabel('Akurasi'); plt.legend()\n",
        "    plt.subplot(1, 2, 2); plt.plot(history.history['loss'], label='Loss Pelatihan'); plt.plot(history.history['val_loss'], label='Loss Validasi'); plt.title(f'Grafik Loss (Dropout = {dropout_rate})'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
        "    plot_path = os.path.join(output_dir, 'grafik_pelatihan.png'); plt.savefig(plot_path); plt.close(); print(f\"Grafik pelatihan telah disimpan di: {plot_path}\")\n",
        "\n",
        "    print(\"\\nMelakukan evaluasi final pada data tes...\")\n",
        "    test_loss, test_accuracy = model_mobilenet_final.evaluate(test_generator); print(f\"Akurasi pada data tes (Dropout = {dropout_rate}): {test_accuracy:.4f}\")\n",
        "\n",
        "    y_pred_probs = model_mobilenet_final.predict(test_generator); y_pred = np.argmax(y_pred_probs, axis=1); y_true = np.array(test_labels)\n",
        "\n",
        "    print(\"\\nLaporan Klasifikasi pada Data Tes:\")\n",
        "    try:\n",
        "        report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True); report_df = pd.DataFrame(report).transpose(); report_path = os.path.join(output_dir, 'classification_report.csv'); report_df.to_csv(report_path); print(classification_report(y_true, y_pred, target_names=class_names)); print(f\"Laporan klasifikasi telah disimpan di: {report_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Tidak dapat membuat laporan klasifikasi: {e}\")\n",
        "\n",
        "    print(\"\\nConfusion Matrix pada Data Tes:\")\n",
        "    cm = confusion_matrix(y_true, y_pred); plt.figure(figsize=(10, 8)); sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names); plt.title(f'Confusion Matrix (Dropout = {dropout_rate})'); plt.ylabel('Kelas Sebenarnya'); plt.xlabel('Kelas Prediksi'); cm_path = os.path.join(output_dir, 'confusion_matrix.png'); plt.savefig(cm_path); plt.close(); print(f\"Confusion matrix telah disimpan di: {cm_path}\")\n",
        "\n",
        "    print(\"\\nMemulai konversi model ke format TensorFlow Lite (.tflite)...\")\n",
        "\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model_mobilenet_final)\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    tflite_model_path = os.path.join(output_dir, 'model.tflite')\n",
        "    with open(tflite_model_path, 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "    print(f\"Model TFLite telah disimpan di: {tflite_model_path}\")\n",
        "\n",
        "    labels_path = os.path.join(output_dir, 'labels.txt')\n",
        "    with open(labels_path, 'w') as f:\n",
        "        for class_name in class_names:\n",
        "            f.write(f\"{class_name}\\n\")\n",
        "    print(f\"File label telah disimpan di: {labels_path}\")\n",
        "\n",
        "    print(f\"\\nPROSES LENGKAP SELESAI UNTUK DROPOUT = {dropout_rate}.\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"SEMUA EKSPERIMEN DROPOUT TELAH SELESAI.\")\n",
        "print(f\"Semua hasil disimpan di direktori: '{base_output_dir}'\")\n",
        "print(f\"{'='*80}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HAJtzYLT5sj"
      },
      "source": [
        "# MobileNetV3 Large Dengan Decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1GVCr7RC5lAU",
        "outputId": "1b89fa0a-de7d-429b-c18c-33d1d101d2bf"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# PROSES 2 & 3: PEMBANGUNAN, PELATIHAN, EVALUASI, DAN PENYIMPANAN MODEL\n",
        "# DENGAN PERBAIKAN UNTUK CUSTOM GENERATOR\n",
        "# ==============================================================================\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
        "from tensorflow.keras.applications import MobileNetV3Large\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Daftar nilai dropout yang akan diuji\n",
        "dropout_values = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "\n",
        "# Direktori utama untuk menyimpan hasil\n",
        "base_output_dir = '/content/drive/MyDrive/hasil_eksperimen_dropout_mobilenetv3_large_decay'\n",
        "os.makedirs(base_output_dir, exist_ok=True)\n",
        "\n",
        "for dropout_rate in dropout_values:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"MEMULAI EKSPERIMEN DENGAN DROPOUT = {dropout_rate} (MobileNetV3-Large)\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    output_dir = os.path.join(base_output_dir, f'dropout_{dropout_rate}')\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    base_model = MobileNetV3Large(input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3), include_top=False, weights='imagenet')\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(dropout_rate, seed=SEED_VALUE)(x)\n",
        "    outputs = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "    model_mobilenet_final = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    initial_learning_rate = 0.001\n",
        "\n",
        "    # Inisialisasi Learning Rate Decay\n",
        "    decay_steps = len(train_generator)\n",
        "    decay_rate = 0.96\n",
        "\n",
        "    lr_schedule = ExponentialDecay(\n",
        "        initial_learning_rate,\n",
        "        decay_steps=decay_steps,\n",
        "        decay_rate=decay_rate,\n",
        "        staircase=True\n",
        "    )\n",
        "\n",
        "    model_mobilenet_final.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    print(\"Arsitektur Model:\")\n",
        "    model_mobilenet_final.summary()\n",
        "\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    print(f\"\\nMemulai pelatihan model dengan dropout = {dropout_rate}...\")\n",
        "    history = model_mobilenet_final.fit(train_generator, epochs=50, validation_data=val_generator, callbacks=[early_stopping], verbose=1)\n",
        "    print(f\"\\nPelatihan model dengan dropout = {dropout_rate} telah selesai.\")\n",
        "\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    plt.subplot(1, 2, 1); plt.plot(history.history['accuracy'], label='Akurasi Pelatihan'); plt.plot(history.history['val_accuracy'], label='Akurasi Validasi'); plt.title(f'Grafik Akurasi (Dropout = {dropout_rate})'); plt.xlabel('Epoch'); plt.ylabel('Akurasi'); plt.legend()\n",
        "    plt.subplot(1, 2, 2); plt.plot(history.history['loss'], label='Loss Pelatihan'); plt.plot(history.history['val_loss'], label='Loss Validasi'); plt.title(f'Grafik Loss (Dropout = {dropout_rate})'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
        "    plot_path = os.path.join(output_dir, 'grafik_pelatihan.png'); plt.savefig(plot_path); plt.close(); print(f\"Grafik pelatihan telah disimpan di: {plot_path}\")\n",
        "\n",
        "    print(\"\\nMelakukan evaluasi final pada data tes...\")\n",
        "    test_loss, test_accuracy = model_mobilenet_final.evaluate(test_generator); print(f\"Akurasi pada data tes (Dropout = {dropout_rate}): {test_accuracy:.4f}\")\n",
        "\n",
        "    y_pred_probs = model_mobilenet_final.predict(test_generator); y_pred = np.argmax(y_pred_probs, axis=1); y_true = np.array(test_labels)\n",
        "\n",
        "    print(\"\\nLaporan Klasifikasi pada Data Tes:\")\n",
        "    try:\n",
        "        report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True); report_df = pd.DataFrame(report).transpose(); report_path = os.path.join(output_dir, 'classification_report.csv'); report_df.to_csv(report_path); print(classification_report(y_true, y_pred, target_names=class_names)); print(f\"Laporan klasifikasi telah disimpan di: {report_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Tidak dapat membuat laporan klasifikasi: {e}\")\n",
        "\n",
        "    print(\"\\nConfusion Matrix pada Data Tes:\")\n",
        "    cm = confusion_matrix(y_true, y_pred); plt.figure(figsize=(10, 8)); sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names); plt.title(f'Confusion Matrix (Dropout = {dropout_rate})'); plt.ylabel('Kelas Sebenarnya'); plt.xlabel('Kelas Prediksi'); cm_path = os.path.join(output_dir, 'confusion_matrix.png'); plt.savefig(cm_path); plt.close(); print(f\"Confusion matrix telah disimpan di: {cm_path}\")\n",
        "\n",
        "    print(\"\\nMemulai konversi model ke format TensorFlow Lite (.tflite)...\")\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model_mobilenet_final)\n",
        "    tflite_model = converter.convert()\n",
        "    tflite_model_path = os.path.join(output_dir, 'model.tflite')\n",
        "    with open(tflite_model_path, 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "    print(f\"Model TFLite telah disimpan di: {tflite_model_path}\")\n",
        "\n",
        "    labels_path = os.path.join(output_dir, 'labels.txt')\n",
        "    with open(labels_path, 'w') as f:\n",
        "        for class_name in class_names:\n",
        "            f.write(f\"{class_name}\\n\")\n",
        "    print(f\"File label telah disimpan di: {labels_path}\")\n",
        "\n",
        "    print(f\"\\nPROSES LENGKAP SELESAI UNTUK DROPOUT = {dropout_rate}.\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"SEMUA EKSPERIMEN DROPOUT TELAH SELESAI.\")\n",
        "print(f\"Semua hasil disimpan di direktori: '{base_output_dir}'\")\n",
        "print(f\"{'='*80}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RimbG1FcUB-E"
      },
      "source": [
        "# Data Loading (MobileNetV3 Small)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zb9J8gFBUKmr"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# PROSES 1: PERSIAPAN DATA (KHUSUS UNTUK MOBILENETV3)\n",
        "# ==============================================================================\n",
        "\n",
        "# Langkah 1.1: Install Library\n",
        "!pip install -q albumentations\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "from collections import Counter\n",
        "import albumentations as A\n",
        "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
        "import random\n",
        "\n",
        "# Langkah 1.2: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Langkah 1.3: Definisi Path dan Parameter\n",
        "DATASET_DIR = '/content/drive/MyDrive/Dataset_Skripsi_Augmented_200_Kran_15'\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "SEED_VALUE = 42\n",
        "def set_seed(seed=42):\n",
        "  \"\"\"\n",
        "  Mengatur seed dan menonaktifkan parallelism untuk hasil yang fully deterministic.\n",
        "  \"\"\"\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  tf.random.set_seed(seed)\n",
        "\n",
        "  # Menjalankan operasi TF pada satu thread untuk menghilangkan randomness dari parallelism\n",
        "  tf.config.threading.set_inter_op_parallelism_threads(1)\n",
        "  tf.config.threading.set_intra_op_parallelism_threads(1)\n",
        "\n",
        "  print(f\"Random seed set to {seed} and parallelism disabled for reproducibility.\")\n",
        "\n",
        "set_seed(SEED_VALUE)\n",
        "\n",
        "# Langkah 1.4: Ambil Nama Kelas dari Struktur Direktori Train\n",
        "train_base_dir = os.path.join(DATASET_DIR, 'train')\n",
        "class_dirs = sorted([d for d in os.listdir(train_base_dir) if os.path.isdir(os.path.join(train_base_dir, d))])\n",
        "class_map = {name: i for i, name in enumerate(class_dirs)}\n",
        "\n",
        "class_names = class_dirs\n",
        "print(f\"Nama kelas: {class_names}\")\n",
        "NUM_CLASSES = len(class_names)\n",
        "print(f\"Jumlah kelas: {NUM_CLASSES}\")\n",
        "\n",
        "# Global lists untuk verifikasi distribusi data\n",
        "train_labels, val_labels, test_labels = [], [], []\n",
        "\n",
        "# Langkah 1.5: Transformasi Gambar\n",
        "basic_transform = A.Compose([\n",
        "    A.Resize(height=IMAGE_SIZE[0], width=IMAGE_SIZE[1])\n",
        "])\n",
        "\n",
        "# Langkah 1.6: Custom Data Generator\n",
        "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, directory, class_map, batch_size, transform, num_classes, shuffle=True, store_global_labels=None):\n",
        "        self.directory = directory\n",
        "        self.class_map = class_map\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transform\n",
        "        self.num_classes = num_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self._load_image_paths()\n",
        "        self.on_epoch_end()\n",
        "\n",
        "        if store_global_labels is not None:\n",
        "            store_global_labels.extend(self.labels)\n",
        "\n",
        "    def _load_image_paths(self):\n",
        "        \"\"\"Memuat path gambar dari direktori yang diberikan.\"\"\"\n",
        "        print(f\"Loading images from: {self.directory}\")\n",
        "        for class_name in sorted(self.class_map.keys()):\n",
        "            class_path = os.path.join(self.directory, class_name)\n",
        "            if os.path.isdir(class_path):\n",
        "                class_idx = self.class_map[class_name]\n",
        "                for fname in sorted(os.listdir(class_path)):\n",
        "                    if fname.lower().endswith('.jpg'):\n",
        "                        fpath = os.path.join(class_path, fname)\n",
        "                        self.image_paths.append(fpath)\n",
        "                        self.labels.append(class_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Menghitung jumlah batch per epoch.\"\"\"\n",
        "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Menghasilkan satu batch data.\"\"\"\n",
        "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch_paths = [self.image_paths[i] for i in indexes]\n",
        "        batch_labels = [self.labels[i] for i in indexes]\n",
        "        batch_images = []\n",
        "\n",
        "        for path in batch_paths:\n",
        "            img = Image.open(path).convert('RGB')\n",
        "            img_cv = np.array(img)\n",
        "            transformed = self.transform(image=img_cv) # Resize Gambar\n",
        "            batch_images.append(transformed['image'])\n",
        "\n",
        "        batch_images = preprocess_input(np.array(batch_images, dtype=np.float32))\n",
        "        batch_labels = tf.keras.utils.to_categorical(batch_labels, num_classes=self.num_classes)\n",
        "        return batch_images, batch_labels\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Mengacak indeks di akhir setiap epoch.\"\"\"\n",
        "        self.indexes = np.arange(len(self.image_paths))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "# Langkah 1.7: Inisialisasi Generator\n",
        "train_generator = CustomDataGenerator(\n",
        "    directory=os.path.join(DATASET_DIR, 'train'),\n",
        "    class_map=class_map,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=basic_transform,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    shuffle=True,\n",
        "    store_global_labels=train_labels\n",
        ")\n",
        "\n",
        "val_generator = CustomDataGenerator(\n",
        "    directory=os.path.join(DATASET_DIR, 'val'),\n",
        "    class_map=class_map,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=basic_transform,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    shuffle=False,\n",
        "    store_global_labels=val_labels\n",
        ")\n",
        "\n",
        "test_generator = CustomDataGenerator(\n",
        "    directory=os.path.join(DATASET_DIR, 'test'),\n",
        "    class_map=class_map,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=basic_transform,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    shuffle=False,\n",
        "    store_global_labels=test_labels\n",
        ")\n",
        "\n",
        "print(f\"\\nTotal gambar train: {len(train_generator.image_paths)}\")\n",
        "print(f\"Total gambar validation: {len(val_generator.image_paths)}\")\n",
        "print(f\"Total gambar test: {len(test_generator.image_paths)}\")\n",
        "\n",
        "print(\"\\nPROSES 1 SELESAI: Data MobileNetV3 siap dari direktori yang sudah di-augmentasi.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# Verifikasi Distribusi Data di Setiap Split\n",
        "# ==============================================================================\n",
        "print(\"\\nVerifikasi Distribusi Data:\")\n",
        "\n",
        "# Menghitung jumlah kemunculan setiap label di setiap set\n",
        "train_counts = Counter(train_labels)\n",
        "val_counts = Counter(val_labels)\n",
        "test_counts = Counter(test_labels)\n",
        "\n",
        "# Membuat tabel untuk visualisasi yang mudah dibaca\n",
        "distribusi_data = {\n",
        "    \"Kelas\": class_names,\n",
        "    \"Jumlah Train\": [train_counts.get(i, 0) for i in range(len(class_names))],\n",
        "    \"Jumlah Validasi\": [val_counts.get(i, 0) for i in range(len(class_names))],\n",
        "    \"Jumlah Test\": [test_counts.get(i, 0) for i in range(len(class_names))],\n",
        "}\n",
        "df_distribusi = pd.DataFrame(distribusi_data)\n",
        "df_distribusi[\"Total per Kelas\"] = df_distribusi[\"Jumlah Train\"] + df_distribusi[\"Jumlah Validasi\"] + df_distribusi[\"Jumlah Test\"]\n",
        "\n",
        "# Menambahkan baris total di bagian bawah\n",
        "total_row = {\n",
        "    \"Kelas\": \"TOTAL\",\n",
        "    \"Jumlah Train\": sum(df_distribusi[\"Jumlah Train\"]),\n",
        "    \"Jumlah Validasi\": sum(df_distribusi[\"Jumlah Validasi\"]),\n",
        "    \"Jumlah Test\": sum(df_distribusi[\"Jumlah Test\"]),\n",
        "    \"Total per Kelas\": sum(df_distribusi[\"Total per Kelas\"])\n",
        "}\n",
        "df_distribusi = pd.concat([df_distribusi, pd.DataFrame([total_row])], ignore_index=True)\n",
        "\n",
        "print(\"Distribusi jumlah data per kelas di setiap split:\")\n",
        "print(df_distribusi.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sgk4NYd1VD6s"
      },
      "source": [
        "# MobileNetV3 Small Tanpa Decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIqCNbAGUKzo"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# PROSES 2 & 3: PEMBANGUNAN, PELATIHAN, EVALUASI, DAN PENYIMPANAN MODEL\n",
        "# ==============================================================================\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
        "from tensorflow.keras.applications import MobileNetV3Small\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Daftar nilai dropout yang akan diuji\n",
        "dropout_values = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "\n",
        "# Direktori utama untuk menyimpan hasil\n",
        "base_output_dir = '/content/drive/MyDrive/hasil_eksperimen_dropout_mobilenetv3_small'\n",
        "os.makedirs(base_output_dir, exist_ok=True)\n",
        "\n",
        "for dropout_rate in dropout_values:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"MEMULAI EKSPERIMEN DENGAN DROPOUT = {dropout_rate} (MobileNetV3-Small)\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    # Membuat sub-direktori untuk setiap nilai dropout\n",
        "    output_dir = os.path.join(base_output_dir, f'dropout_{dropout_rate}')\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # --- PROSES 2: Pembangunan Arsitektur ---\n",
        "    base_model = MobileNetV3Small(\n",
        "        input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(dropout_rate, seed=SEED_VALUE)(x)\n",
        "    outputs = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "    model_mobilenet_final = Model(inputs=inputs, outputs=outputs)\n",
        "    model_mobilenet_final.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    print(\"Arsitektur Model:\")\n",
        "    model_mobilenet_final.summary()\n",
        "\n",
        "    # --- PROSES 3: Pelatihan dan Evaluasi ---\n",
        "    # Langkah 3.1: Melatih Model\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    print(f\"\\nMemulai pelatihan model dengan dropout = {dropout_rate}...\")\n",
        "    history = model_mobilenet_final.fit(\n",
        "        train_generator,\n",
        "        epochs=50,\n",
        "        validation_data=val_generator,\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "    print(f\"\\nPelatihan model dengan dropout = {dropout_rate} telah selesai.\")\n",
        "\n",
        "    # Langkah 3.2: Visualisasi dan Simpan Plot\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Akurasi Pelatihan')\n",
        "    plt.plot(history.history['val_accuracy'], label='Akurasi Validasi')\n",
        "    plt.title(f'Grafik Akurasi (Dropout = {dropout_rate})')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Akurasi'); plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Loss Pelatihan')\n",
        "    plt.plot(history.history['val_loss'], label='Loss Validasi')\n",
        "    plt.title(f'Grafik Loss (Dropout = {dropout_rate})')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
        "    plot_path = os.path.join(output_dir, 'grafik_pelatihan.png')\n",
        "    plt.savefig(plot_path)\n",
        "    plt.close()\n",
        "    print(f\"Grafik pelatihan telah disimpan di: {plot_path}\")\n",
        "\n",
        "    # Langkah 3.3: Evaluasi Final dan Simpan Metrik\n",
        "    print(\"\\nMelakukan evaluasi final pada data tes...\")\n",
        "    test_loss, test_accuracy = model_mobilenet_final.evaluate(test_generator)\n",
        "    print(f\"Akurasi pada data tes (Dropout = {dropout_rate}): {test_accuracy:.4f}\")\n",
        "\n",
        "    y_pred_probs = model_mobilenet_final.predict(test_generator)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    y_true = np.array(test_labels)\n",
        "\n",
        "    print(\"\\nLaporan Klasifikasi pada Data Tes:\")\n",
        "    try:\n",
        "        report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
        "        report_df = pd.DataFrame(report).transpose()\n",
        "        report_path = os.path.join(output_dir, 'classification_report.csv')\n",
        "        report_df.to_csv(report_path)\n",
        "        print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "        print(f\"Laporan klasifikasi telah disimpan di: {report_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Tidak dapat membuat laporan klasifikasi: {e}\")\n",
        "\n",
        "    print(\"\\nConfusion Matrix pada Data Tes:\")\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(f'Confusion Matrix (Dropout = {dropout_rate})')\n",
        "    plt.ylabel('Kelas Sebenarnya'); plt.xlabel('Kelas Prediksi')\n",
        "    cm_path = os.path.join(output_dir, 'confusion_matrix.png')\n",
        "    plt.savefig(cm_path)\n",
        "    plt.close()\n",
        "    print(f\"Confusion matrix telah disimpan di: {cm_path}\")\n",
        "\n",
        "    # Langkah 3.4: Konversi dan Simpan Model untuk Flutter\n",
        "    print(\"\\nMemulai konversi model ke format TensorFlow Lite (.tflite)...\")\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model_mobilenet_final)\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    tflite_model_path = os.path.join(output_dir, 'model.tflite')\n",
        "    with open(tflite_model_path, 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "    print(f\"Model TFLite telah disimpan di: {tflite_model_path}\")\n",
        "\n",
        "    labels_path = os.path.join(output_dir, 'labels.txt')\n",
        "    with open(labels_path, 'w') as f:\n",
        "        for class_name in class_names:\n",
        "            f.write(f\"{class_name}\\n\")\n",
        "    print(f\"File label telah disimpan di: {labels_path}\")\n",
        "\n",
        "    print(f\"\\nPROSES LENGKAP SELESAI UNTUK DROPOUT = {dropout_rate}.\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"SEMUA EKSPERIMEN DROPOUT TELAH SELESAI.\")\n",
        "print(f\"Semua hasil disimpan di direktori: '{base_output_dir}'\")\n",
        "print(f\"{'='*80}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXGUgHGbVH9Q"
      },
      "source": [
        "# MobileNetV3 Small Dengan Decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDqoXmBzUK6o"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# PROSES 2 & 3: PEMBANGUNAN, PELATIHAN, EVALUASI, DAN PENYIMPANAN MODEL\n",
        "# ==============================================================================\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
        "from tensorflow.keras.applications import MobileNetV3Small\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Daftar nilai dropout yang akan diuji\n",
        "dropout_values = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "\n",
        "# Direktori utama untuk menyimpan hasil\n",
        "base_output_dir = '/content/drive/MyDrive/hasil_eksperimen_dropout_mobilenetv3_small_decay'\n",
        "os.makedirs(base_output_dir, exist_ok=True)\n",
        "\n",
        "for dropout_rate in dropout_values:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"MEMULAI EKSPERIMEN DENGAN DROPOUT = {dropout_rate} (MobileNetV3-Small)\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    # Membuat sub-direktori untuk setiap nilai dropout\n",
        "    output_dir = os.path.join(base_output_dir, f'dropout_{dropout_rate}')\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # --- PROSES 2: Pembangunan Arsitektur ---\n",
        "    base_model = MobileNetV3Small(\n",
        "        input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(dropout_rate, seed=SEED_VALUE)(x)\n",
        "    outputs = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "    model_mobilenet_final = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Inisialisasi Decay\n",
        "    initial_learning_rate = 0.001\n",
        "    decay_steps = len(train_generator)\n",
        "    decay_rate = 0.96\n",
        "\n",
        "    lr_schedule = ExponentialDecay(\n",
        "        initial_learning_rate,\n",
        "        decay_steps=decay_steps,\n",
        "        decay_rate=decay_rate,\n",
        "        staircase=True\n",
        "    )\n",
        "\n",
        "    # Perubahan 3: Gunakan schedule pada optimizer\n",
        "    model_mobilenet_final.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    print(\"Arsitektur Model:\")\n",
        "    model_mobilenet_final.summary()\n",
        "\n",
        "    # --- PROSES 3: Pelatihan dan Evaluasi ---\n",
        "    # Langkah 3.1: Melatih Model\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    print(f\"\\nMemulai pelatihan model dengan dropout = {dropout_rate}...\")\n",
        "    history = model_mobilenet_final.fit(\n",
        "        train_generator,\n",
        "        epochs=50,\n",
        "        validation_data=val_generator,\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "    print(f\"\\nPelatihan model dengan dropout = {dropout_rate} telah selesai.\")\n",
        "\n",
        "    # Langkah 3.2: Visualisasi dan Simpan Plot\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Akurasi Pelatihan')\n",
        "    plt.plot(history.history['val_accuracy'], label='Akurasi Validasi')\n",
        "    plt.title(f'Grafik Akurasi (Dropout = {dropout_rate})')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Akurasi'); plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Loss Pelatihan')\n",
        "    plt.plot(history.history['val_loss'], label='Loss Validasi')\n",
        "    plt.title(f'Grafik Loss (Dropout = {dropout_rate})')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
        "    plot_path = os.path.join(output_dir, 'grafik_pelatihan.png')\n",
        "    plt.savefig(plot_path)\n",
        "    plt.close()\n",
        "    print(f\"Grafik pelatihan telah disimpan di: {plot_path}\")\n",
        "\n",
        "    # Langkah 3.3: Evaluasi Final dan Simpan Metrik\n",
        "    print(\"\\nMelakukan evaluasi final pada data tes...\")\n",
        "    test_loss, test_accuracy = model_mobilenet_final.evaluate(test_generator)\n",
        "    print(f\"Akurasi pada data tes (Dropout = {dropout_rate}): {test_accuracy:.4f}\")\n",
        "\n",
        "    y_pred_probs = model_mobilenet_final.predict(test_generator)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    y_true = np.array(test_labels)\n",
        "\n",
        "    print(\"\\nLaporan Klasifikasi pada Data Tes:\")\n",
        "    try:\n",
        "        report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
        "        report_df = pd.DataFrame(report).transpose()\n",
        "        report_path = os.path.join(output_dir, 'classification_report.csv')\n",
        "        report_df.to_csv(report_path)\n",
        "        print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "        print(f\"Laporan klasifikasi telah disimpan di: {report_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Tidak dapat membuat laporan klasifikasi: {e}\")\n",
        "\n",
        "    print(\"\\nConfusion Matrix pada Data Tes:\")\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(f'Confusion Matrix (Dropout = {dropout_rate})')\n",
        "    plt.ylabel('Kelas Sebenarnya'); plt.xlabel('Kelas Prediksi')\n",
        "    cm_path = os.path.join(output_dir, 'confusion_matrix.png')\n",
        "    plt.savefig(cm_path)\n",
        "    plt.close()\n",
        "    print(f\"Confusion matrix telah disimpan di: {cm_path}\")\n",
        "\n",
        "    # Langkah 3.4: Konversi dan Simpan Model untuk Flutter\n",
        "    print(\"\\nMemulai konversi model ke format TensorFlow Lite (.tflite)...\")\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model_mobilenet_final)\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    tflite_model_path = os.path.join(output_dir, 'model.tflite')\n",
        "    with open(tflite_model_path, 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "    print(f\"Model TFLite telah disimpan di: {tflite_model_path}\")\n",
        "\n",
        "    labels_path = os.path.join(output_dir, 'labels.txt')\n",
        "    with open(labels_path, 'w') as f:\n",
        "        for class_name in class_names:\n",
        "            f.write(f\"{class_name}\\n\")\n",
        "    print(f\"File label telah disimpan di: {labels_path}\")\n",
        "\n",
        "    print(f\"\\nPROSES LENGKAP SELESAI UNTUK DROPOUT = {dropout_rate}.\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"SEMUA EKSPERIMEN DROPOUT TELAH SELESAI.\")\n",
        "print(f\"Semua hasil disimpan di direktori: '{base_output_dir}'\")\n",
        "print(f\"{'='*80}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiPgl_HcV4BT"
      },
      "source": [
        "# Data Loading (MobileNetV2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVYdHllcV29e"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# PROSES 1: PERSIAPAN DATA (KHUSUS UNTUK MOBILENETV2)\n",
        "# ==============================================================================\n",
        "\n",
        "# Langkah 1.1: Install Library\n",
        "!pip install -q albumentations\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "from collections import Counter\n",
        "import albumentations as A\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "import random\n",
        "\n",
        "# Langkah 1.2: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Langkah 1.3: Definisi Path dan Parameter\n",
        "DATASET_DIR = '/content/drive/MyDrive/Dataset_Skripsi_Augmented_200_Kran_15'\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "SEED_VALUE = 42\n",
        "def set_seed(seed=42):\n",
        "  \"\"\"\n",
        "  Mengatur seed dan menonaktifkan parallelism untuk hasil yang fully deterministic.\n",
        "  \"\"\"\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  tf.random.set_seed(seed)\n",
        "\n",
        "  # Menjalankan operasi TF pada satu thread untuk menghilangkan randomness dari parallelism\n",
        "  tf.config.threading.set_inter_op_parallelism_threads(1)\n",
        "  tf.config.threading.set_intra_op_parallelism_threads(1)\n",
        "\n",
        "  print(f\"Random seed set to {seed} and parallelism disabled for reproducibility.\")\n",
        "\n",
        "set_seed(SEED_VALUE)\n",
        "\n",
        "# Langkah 1.4: Ambil Nama Kelas dari Struktur Direktori Train\n",
        "train_base_dir = os.path.join(DATASET_DIR, 'train')\n",
        "class_dirs = sorted([d for d in os.listdir(train_base_dir) if os.path.isdir(os.path.join(train_base_dir, d))])\n",
        "class_map = {name: i for i, name in enumerate(class_dirs)}\n",
        "\n",
        "class_names = class_dirs\n",
        "print(f\"Nama kelas: {class_names}\")\n",
        "NUM_CLASSES = len(class_names)\n",
        "print(f\"Jumlah kelas: {NUM_CLASSES}\")\n",
        "\n",
        "# Global lists untuk verifikasi distribusi data\n",
        "train_labels, val_labels, test_labels = [], [], []\n",
        "\n",
        "# Langkah 1.5: Transformasi Gambar\n",
        "basic_transform = A.Compose([\n",
        "    A.Resize(height=IMAGE_SIZE[0], width=IMAGE_SIZE[1])\n",
        "])\n",
        "\n",
        "# Langkah 1.6: Custom Data Generator\n",
        "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, directory, class_map, batch_size, transform, num_classes, shuffle=True, store_global_labels=None):\n",
        "        self.directory = directory\n",
        "        self.class_map = class_map\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transform\n",
        "        self.num_classes = num_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self._load_image_paths()\n",
        "        self.on_epoch_end()\n",
        "\n",
        "        if store_global_labels is not None:\n",
        "            store_global_labels.extend(self.labels)\n",
        "\n",
        "    def _load_image_paths(self):\n",
        "        \"\"\"Memuat path gambar dari direktori yang diberikan.\"\"\"\n",
        "        print(f\"Loading images from: {self.directory}\")\n",
        "        for class_name in sorted(self.class_map.keys()):\n",
        "            class_path = os.path.join(self.directory, class_name)\n",
        "            if os.path.isdir(class_path):\n",
        "                class_idx = self.class_map[class_name]\n",
        "                for fname in sorted(os.listdir(class_path)):\n",
        "                    if fname.lower().endswith('.jpg'):\n",
        "                        fpath = os.path.join(class_path, fname)\n",
        "                        self.image_paths.append(fpath)\n",
        "                        self.labels.append(class_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Menghitung jumlah batch per epoch.\"\"\"\n",
        "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Menghasilkan satu batch data.\"\"\"\n",
        "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch_paths = [self.image_paths[i] for i in indexes]\n",
        "        batch_labels = [self.labels[i] for i in indexes]\n",
        "        batch_images = []\n",
        "\n",
        "        for path in batch_paths:\n",
        "            img = Image.open(path).convert('RGB')\n",
        "            img_cv = np.array(img)\n",
        "            transformed = self.transform(image=img_cv) # Resize Gambar\n",
        "            batch_images.append(transformed['image'])\n",
        "\n",
        "        batch_images = preprocess_input(np.array(batch_images, dtype=np.float32))\n",
        "        batch_labels = tf.keras.utils.to_categorical(batch_labels, num_classes=self.num_classes)\n",
        "        return batch_images, batch_labels\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Mengacak indeks di akhir setiap epoch.\"\"\"\n",
        "        self.indexes = np.arange(len(self.image_paths))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "# Langkah 1.7: Inisialisasi Generator\n",
        "train_generator = CustomDataGenerator(\n",
        "    directory=os.path.join(DATASET_DIR, 'train'),\n",
        "    class_map=class_map,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=basic_transform,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    shuffle=True,\n",
        "    store_global_labels=train_labels\n",
        ")\n",
        "\n",
        "val_generator = CustomDataGenerator(\n",
        "    directory=os.path.join(DATASET_DIR, 'val'),\n",
        "    class_map=class_map,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=basic_transform,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    shuffle=False,\n",
        "    store_global_labels=val_labels\n",
        ")\n",
        "\n",
        "test_generator = CustomDataGenerator(\n",
        "    directory=os.path.join(DATASET_DIR, 'test'),\n",
        "    class_map=class_map,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=basic_transform,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    shuffle=False,\n",
        "    store_global_labels=test_labels\n",
        ")\n",
        "\n",
        "print(f\"\\nTotal gambar train: {len(train_generator.image_paths)}\")\n",
        "print(f\"Total gambar validation: {len(val_generator.image_paths)}\")\n",
        "print(f\"Total gambar test: {len(test_generator.image_paths)}\")\n",
        "\n",
        "print(\"\\nPROSES 1 SELESAI: Data MobileNetV2 siap dari direktori yang sudah di-augmentasi.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# Verifikasi Distribusi Data di Setiap Split\n",
        "# ==============================================================================\n",
        "print(\"\\nVerifikasi Distribusi Data:\")\n",
        "\n",
        "# Menghitung jumlah kemunculan setiap label di setiap set\n",
        "train_counts = Counter(train_labels)\n",
        "val_counts = Counter(val_labels)\n",
        "test_counts = Counter(test_labels)\n",
        "\n",
        "# Membuat tabel untuk visualisasi yang mudah dibaca\n",
        "distribusi_data = {\n",
        "    \"Kelas\": class_names,\n",
        "    \"Jumlah Train\": [train_counts.get(i, 0) for i in range(len(class_names))],\n",
        "    \"Jumlah Validasi\": [val_counts.get(i, 0) for i in range(len(class_names))],\n",
        "    \"Jumlah Test\": [test_counts.get(i, 0) for i in range(len(class_names))],\n",
        "}\n",
        "df_distribusi = pd.DataFrame(distribusi_data)\n",
        "df_distribusi[\"Total per Kelas\"] = df_distribusi[\"Jumlah Train\"] + df_distribusi[\"Jumlah Validasi\"] + df_distribusi[\"Jumlah Test\"]\n",
        "\n",
        "# Menambahkan baris total di bagian bawah\n",
        "total_row = {\n",
        "    \"Kelas\": \"TOTAL\",\n",
        "    \"Jumlah Train\": sum(df_distribusi[\"Jumlah Train\"]),\n",
        "    \"Jumlah Validasi\": sum(df_distribusi[\"Jumlah Validasi\"]),\n",
        "    \"Jumlah Test\": sum(df_distribusi[\"Jumlah Test\"]),\n",
        "    \"Total per Kelas\": sum(df_distribusi[\"Total per Kelas\"])\n",
        "}\n",
        "df_distribusi = pd.concat([df_distribusi, pd.DataFrame([total_row])], ignore_index=True)\n",
        "\n",
        "print(\"Distribusi jumlah data per kelas di setiap split:\")\n",
        "print(df_distribusi.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX4NQkeFV4wp"
      },
      "source": [
        "# MobileNetV2 Tanpa Decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSx7WCsVV3Av"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# PROSES 2 & 3: PEMBANGUNAN, PELATIHAN, EVALUASI, DAN PENYIMPANAN MODEL\n",
        "# ==============================================================================\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Daftar nilai dropout yang akan diuji\n",
        "dropout_values = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "\n",
        "# Direktori utama untuk menyimpan hasil\n",
        "base_output_dir = '/content/drive/MyDrive/hasil_eksperimen_dropout_mobilenetv2'\n",
        "os.makedirs(base_output_dir, exist_ok=True)\n",
        "\n",
        "for dropout_rate in dropout_values:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"MEMULAI EKSPERIMEN DENGAN DROPOUT = {dropout_rate} (MobileNetV2)\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    # Membuat sub-direktori untuk setiap nilai dropout\n",
        "    output_dir = os.path.join(base_output_dir, f'dropout_{dropout_rate}')\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # --- PROSES 2: Pembangunan Arsitektur ---\n",
        "    base_model = MobileNetV2(\n",
        "        input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(dropout_rate, seed=SEED_VALUE)(x)\n",
        "    outputs = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "    model_mobilenet_final = Model(inputs=inputs, outputs=outputs)\n",
        "    model_mobilenet_final.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    print(\"Arsitektur Model:\")\n",
        "    model_mobilenet_final.summary()\n",
        "\n",
        "    # --- PROSES 3: Pelatihan dan Evaluasi ---\n",
        "    # Langkah 3.1: Melatih Model\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    print(f\"\\nMemulai pelatihan model dengan dropout = {dropout_rate}...\")\n",
        "    history = model_mobilenet_final.fit(\n",
        "        train_generator,\n",
        "        epochs=50,\n",
        "        validation_data=val_generator,\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "    print(f\"\\nPelatihan model dengan dropout = {dropout_rate} telah selesai.\")\n",
        "\n",
        "    # Langkah 3.2: Visualisasi dan Simpan Plot\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Akurasi Pelatihan')\n",
        "    plt.plot(history.history['val_accuracy'], label='Akurasi Validasi')\n",
        "    plt.title(f'Grafik Akurasi (Dropout = {dropout_rate})')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Akurasi'); plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Loss Pelatihan')\n",
        "    plt.plot(history.history['val_loss'], label='Loss Validasi')\n",
        "    plt.title(f'Grafik Loss (Dropout = {dropout_rate})')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
        "    plot_path = os.path.join(output_dir, 'grafik_pelatihan.png')\n",
        "    plt.savefig(plot_path)\n",
        "    plt.close()\n",
        "    print(f\"Grafik pelatihan telah disimpan di: {plot_path}\")\n",
        "\n",
        "    # Langkah 3.3: Evaluasi Final dan Simpan Metrik\n",
        "    print(\"\\nMelakukan evaluasi final pada data tes...\")\n",
        "    test_loss, test_accuracy = model_mobilenet_final.evaluate(test_generator)\n",
        "    print(f\"Akurasi pada data tes (Dropout = {dropout_rate}): {test_accuracy:.4f}\")\n",
        "\n",
        "    y_pred_probs = model_mobilenet_final.predict(test_generator)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    y_true = np.array(test_labels)\n",
        "\n",
        "    print(\"\\nLaporan Klasifikasi pada Data Tes:\")\n",
        "    try:\n",
        "        report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
        "        report_df = pd.DataFrame(report).transpose()\n",
        "        report_path = os.path.join(output_dir, 'classification_report.csv')\n",
        "        report_df.to_csv(report_path)\n",
        "        print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "        print(f\"Laporan klasifikasi telah disimpan di: {report_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Tidak dapat membuat laporan klasifikasi: {e}\")\n",
        "\n",
        "    print(\"\\nConfusion Matrix pada Data Tes:\")\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(f'Confusion Matrix (Dropout = {dropout_rate})')\n",
        "    plt.ylabel('Kelas Sebenarnya'); plt.xlabel('Kelas Prediksi')\n",
        "    cm_path = os.path.join(output_dir, 'confusion_matrix.png')\n",
        "    plt.savefig(cm_path)\n",
        "    plt.close()\n",
        "    print(f\"Confusion matrix telah disimpan di: {cm_path}\")\n",
        "\n",
        "    # Langkah 3.4: Konversi dan Simpan Model untuk Flutter\n",
        "    print(\"\\nMemulai konversi model ke format TensorFlow Lite (.tflite)...\")\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model_mobilenet_final)\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    tflite_model_path = os.path.join(output_dir, 'model.tflite')\n",
        "    with open(tflite_model_path, 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "    print(f\"Model TFLite telah disimpan di: {tflite_model_path}\")\n",
        "\n",
        "    labels_path = os.path.join(output_dir, 'labels.txt')\n",
        "    with open(labels_path, 'w') as f:\n",
        "        for class_name in class_names:\n",
        "            f.write(f\"{class_name}\\n\")\n",
        "    print(f\"File label telah disimpan di: {labels_path}\")\n",
        "\n",
        "    print(f\"\\nPROSES LENGKAP SELESAI UNTUK DROPOUT = {dropout_rate}.\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"SEMUA EKSPERIMEN DROPOUT TELAH SELESAI.\")\n",
        "print(f\"Semua hasil disimpan di direktori: '{base_output_dir}'\")\n",
        "print(f\"{'='*80}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XhJEBrkV5fh"
      },
      "source": [
        "# MobileNetV2 Dengan Decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlyxpX40V3Q1"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# PROSES 2 & 3: PEMBANGUNAN, PELATIHAN, EVALUASI, DAN PENYIMPANAN MODEL\n",
        "# ==============================================================================\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Daftar nilai dropout yang akan diuji\n",
        "dropout_values = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "\n",
        "# Direktori utama untuk menyimpan hasil\n",
        "base_output_dir = '/content/drive/MyDrive/hasil_eksperimen_dropout_mobilenetv2_decay'\n",
        "os.makedirs(base_output_dir, exist_ok=True)\n",
        "\n",
        "for dropout_rate in dropout_values:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"MEMULAI EKSPERIMEN DENGAN DROPOUT = {dropout_rate} (MobileNetV2)\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    # Membuat sub-direktori untuk setiap nilai dropout\n",
        "    output_dir = os.path.join(base_output_dir, f'dropout_{dropout_rate}')\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # --- PROSES 2: Pembangunan Arsitektur ---\n",
        "    base_model = MobileNetV2(\n",
        "        input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(dropout_rate, seed=SEED_VALUE)(x)\n",
        "    outputs = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "    model_mobilenet_final = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Inisialisasi Decay\n",
        "    initial_learning_rate = 0.001\n",
        "    decay_steps = len(train_generator)\n",
        "    decay_rate = 0.96\n",
        "\n",
        "    lr_schedule = ExponentialDecay(\n",
        "        initial_learning_rate,\n",
        "        decay_steps=decay_steps,\n",
        "        decay_rate=decay_rate,\n",
        "        staircase=True\n",
        "    )\n",
        "\n",
        "    model_mobilenet_final.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    print(\"Arsitektur Model:\")\n",
        "    model_mobilenet_final.summary()\n",
        "\n",
        "    # --- PROSES 3: Pelatihan dan Evaluasi ---\n",
        "    # Langkah 3.1: Melatih Model\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    print(f\"\\nMemulai pelatihan model dengan dropout = {dropout_rate}...\")\n",
        "    history = model_mobilenet_final.fit(\n",
        "        train_generator,\n",
        "        epochs=50,\n",
        "        validation_data=val_generator,\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "    print(f\"\\nPelatihan model dengan dropout = {dropout_rate} telah selesai.\")\n",
        "\n",
        "    # Langkah 3.2: Visualisasi dan Simpan Plot\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Akurasi Pelatihan')\n",
        "    plt.plot(history.history['val_accuracy'], label='Akurasi Validasi')\n",
        "    plt.title(f'Grafik Akurasi (Dropout = {dropout_rate})')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Akurasi'); plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Loss Pelatihan')\n",
        "    plt.plot(history.history['val_loss'], label='Loss Validasi')\n",
        "    plt.title(f'Grafik Loss (Dropout = {dropout_rate})')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
        "    plot_path = os.path.join(output_dir, 'grafik_pelatihan.png')\n",
        "    plt.savefig(plot_path)\n",
        "    plt.close()\n",
        "    print(f\"Grafik pelatihan telah disimpan di: {plot_path}\")\n",
        "\n",
        "    # Langkah 3.3: Evaluasi Final dan Simpan Metrik\n",
        "    print(\"\\nMelakukan evaluasi final pada data tes...\")\n",
        "    test_loss, test_accuracy = model_mobilenet_final.evaluate(test_generator)\n",
        "    print(f\"Akurasi pada data tes (Dropout = {dropout_rate}): {test_accuracy:.4f}\")\n",
        "\n",
        "    y_pred_probs = model_mobilenet_final.predict(test_generator)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    y_true = np.array(test_labels)\n",
        "\n",
        "    print(\"\\nLaporan Klasifikasi pada Data Tes:\")\n",
        "    try:\n",
        "        report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
        "        report_df = pd.DataFrame(report).transpose()\n",
        "        report_path = os.path.join(output_dir, 'classification_report.csv')\n",
        "        report_df.to_csv(report_path)\n",
        "        print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "        print(f\"Laporan klasifikasi telah disimpan di: {report_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Tidak dapat membuat laporan klasifikasi: {e}\")\n",
        "\n",
        "    print(\"\\nConfusion Matrix pada Data Tes:\")\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(f'Confusion Matrix (Dropout = {dropout_rate})')\n",
        "    plt.ylabel('Kelas Sebenarnya'); plt.xlabel('Kelas Prediksi')\n",
        "    cm_path = os.path.join(output_dir, 'confusion_matrix.png')\n",
        "    plt.savefig(cm_path)\n",
        "    plt.close()\n",
        "    print(f\"Confusion matrix telah disimpan di: {cm_path}\")\n",
        "\n",
        "    # Langkah 3.4: Konversi dan Simpan Model untuk Flutter\n",
        "    print(\"\\nMemulai konversi model ke format TensorFlow Lite (.tflite)...\")\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model_mobilenet_final)\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    tflite_model_path = os.path.join(output_dir, 'model.tflite')\n",
        "    with open(tflite_model_path, 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "    print(f\"Model TFLite telah disimpan di: {tflite_model_path}\")\n",
        "\n",
        "    labels_path = os.path.join(output_dir, 'labels.txt')\n",
        "    with open(labels_path, 'w') as f:\n",
        "        for class_name in class_names:\n",
        "            f.write(f\"{class_name}\\n\")\n",
        "    print(f\"File label telah disimpan di: {labels_path}\")\n",
        "\n",
        "    print(f\"\\nPROSES LENGKAP SELESAI UNTUK DROPOUT = {dropout_rate}.\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"SEMUA EKSPERIMEN DROPOUT TELAH SELESAI.\")\n",
        "print(f\"Semua hasil disimpan di direktori: '{base_output_dir}'\")\n",
        "print(f\"{'='*80}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
